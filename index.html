---
layout: home
---

<div class='container'>
  <header class="masthead text-center">

    <!--=================Biography==========================-->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="30">
      <tr>
        <td width="67%" valign="middle">
          <p align="center">
            <name>Liangbin Xie</name>
          </p>
          <p align="left">
            Liangbin Xie is a student at SIAT-CAS <i>(Shenzhen)</i>.
          </p>
          <p align="left">
            Liangbin Xie is currently a third-year M.S. student in <a href="https://xpixel.group/">X-Pixel</a> at
            Shenzhen Institute of Advanced Technology,
            Chinese
            Academy of Science. He is supervised by Prof. <a
              href=" https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>.
            He received his B.Eng. degree from Northeastern University, Shenyang, China.
          </p>
          <p align="left">
            His research interests include computer vision and deep learning, particularly focusing on image restoration
            and video restoration, <i>etc</i>.
          </p>

        </td>
        <td width="33%">

          <center>
            <img src="images/me.jpg" , width="70%"></a><br><br>
          </center>

          <!-- <div style="width:1px; height:1px; visibility:hidden; overflow:hidden">
            <img class='img-responsive center-block' src="/images/me.jpg" />
          </div>
          <img class='img-responsive center-block' src="/images/me.jpg" width="70%" height="70%"
            onmouseover="this.src='/images/me.jpg'" width="70%" height="70%" onmouseout="this.src='/images/me.jpg'"
            width="70%" height="70%" /> -->
        </td>
      </tr>
    </table>
    <div align="left" style="margin-top: -35px;"></div>

    <div align="left" style="margin-top: 10px;margin-bottom: 30px;">
      &nbsp;&nbsp;<a href="https://github.com/LiangbinXie"><i style="font-size:26px" class="fa fa-github"></i>
        <font size="4"> Github </font>
      </a>
    </div>

    <!--=================News==========================-->
    <h3 align="left"><a id="news"></a> <br>News</h3>
    <ul style="list-style: none;">
      <li><span class="glyphicon glyphicon-th-list"></span>
        [05/2022] One paper to appear in CVPR 2022 workshop: <a href="">VFHQ:
          A High-Quality Dataset and Benchmark for Video Face Super-Resolution</a>.
      </li>
      <li><span class="glyphicon glyphicon-th-list"></span>
        [12/2021] One paper to appear in NeurIPS 2021 as spotlight (2.85%): <a
          href="https://proceedings.neurips.cc/paper/2021/hash/008bd5ad93b754d500338c253d9c1770-Abstract.html">FAIG:
          Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution</a>. Codes are released in
        <a href="https://github.com/TencentARC/FAIG">TencentARC/FAIG</a>
      </li>
      <li><span class="glyphicon glyphicon-th-list"></span>
        [10/2021] <a href="https://arxiv.org/abs/2107.10833">Real-ESRGAN</a> is accepted by ICCV 2021 AIM workshop with
        Honorary Nomiation Paper Award
      </li>
      <li><span class="glyphicon glyphicon-th-list"></span>
        [12/2020] Join ARC Lab (Tencent PCG) as a research intern, work with <a
          href="https://xinntao.github.io/">Xintao</a>.
      </li>
      <li><span class="glyphicon glyphicon-th-list"></span>
        [08/2020] Our video interpolation method, <b>EQVI</b>, won the <a
          href="https://data.vision.ee.ethz.ch/cvl/aim20/">AIM 2020 Challenge on Video Temporal
          Super-Resolution</a>. Check <a href="https://arxiv.org/abs/2009.04642">our paper</a> for more details.
      </li>


    </ul>
    <!--=================Others==========================-->
    <!-- <h4 align="left">Others</h4>
    <p align="left"><a href="https://xinntao.github.io/records/index.html">一些记录</a></p> -->


    <!--=================Publications==========================-->
    <h3 align="left"> <a id="publication"></a> <br>Publications</h3>
    <!--<h4>2018</h4>-->


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
      <!--=======VFHQ: A High-Quality Dataset and Benchmark for Video Face Super-Resolution======-->
      <tr>
        <td width="35%">
          <div class="paper-img"><img style="width: 240px" align="middle" src='./images/vfhq.png'></div>
        </td>
        <td align="left" valign="top" width="65%">
          <paper-title><a href="" target="_blank"><b>VFHQ</b>: A High-Quality Dataset
              and Benchmark for Video Face Super-Resolution</a>
          </paper-title>
          <div class=" paper-info">
            <b>Liangbie Xie</b>,
            <a href="https://xinntao.github.io/">Xintao Wang</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=KjQLROoAAAAJ">Honglun Zhang</a>,
            <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>,
            <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a>
            <br>
            <em>Computer Vision and Pattern Recognition Workshops (CVPRW), 2022.</em>
          </div>
          <span class=" block-text">
            <a href="" target="_blank"> <strong>&nbsp;Paper
                (arXiv)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="http://LiangbinXie.github.io/projects/vfhq" target="_blank"> <strong>&nbsp;Project
                Page&nbsp;</strong></a></span>
          <span class=" block-text">
            <span class=" block-text">
              <a href="" target="_blank"> <strong>&nbsp;Codes
                  (GitHub)&nbsp;</strong></a></span>
            <span class=" block-text">
              <a href="projects/bib/faig_bib.html" target="_blank">
                <strong>&nbsp;BibTex&nbsp;</strong></a>
            </span>
        </td>
      </tr>
      <!--=======Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution======-->
      <tr>
        <td width="35%">
          <div class="paper-img"><img style="width: 240px" align="middle" src='./images/faig.png'></div>
        </td>
        <td align="left" valign="top" width="65%">
          <paper-title><a href="https://arxiv.org/abs/2108.01070" target="_blank"><b>FAIG</b>: Finding Discriminative
              Filters for Specific Degradations in Blind Super-Resolution</a>
          </paper-title>
          <div class=" paper-info">
            <b>Liangbie Xie*</b>,
            <a href="https://xinntao.github.io/">Xintao Wang*</a>,
            <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>,
            <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a>
            <br>
            <em>(* equal contribution) </em><br>
            <em>Advances in Neural Information Processing Systems (NeurIPS), 2021, <b>spotlight (2.85%)</b></em>
          </div>
          <span class=" block-text">
            <a href="https://arxiv.org/abs/2108.01070" target="_blank"> <strong>&nbsp;Paper
                (arXiv)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="https://github.com/TencentARC/FAIG" target="_blank"> <strong>&nbsp;Codes
                (GitHub)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="projects/bib/faig_bib.html" target="_blank">
              <strong>&nbsp;BibTex&nbsp;</strong></a>
          </span>
        </td>
      </tr>
      <!--=======Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data======-->
      <tr>
        <td width="35%">
          <div class="paper-img"><img style="width: 240px" align="middle" src='./images/realesrgan_rlt.jpg'></div>
        </td>
        <td align="left" valign="top" width="65%">
          <paper-title><a href="https://github.com/xinntao/Real-ESRGAN" target="_blank"><b>Real-ESRGAN</b>: Training
              Real-World Blind Super-Resolution with Pure Synthetic Data</a>
          </paper-title>
          <div class=" paper-info">
            <a href="https://xinntao.github.io/">Xintao Wang</a>,
            <b>Liangbie Xie</b>,
            <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>,
            <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a>
            <br>
            <em>International Conference on Computer Vision Workshops (ICCVW), 2021.</em>
          </div>
          <span class=" block-text">
            <a href="https://arxiv.org/abs/2107.10833" target="_blank"> <strong>&nbsp;Paper
                (arXiv)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="https://github.com/xinntao/Real-ESRGAN" target="_blank"> <strong>&nbsp;Codes
                (GitHub)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="projects/bib/realesrgan_bib.html" target="_blank">
              <strong>&nbsp;BibTex&nbsp;</strong></a>
          </span>
        </td>
      </tr>
      <!--=======EQVI: Enhanced Quadratic Video Interpolation======-->
      <tr>
        <td width="35%">
          <div class="paper-img"><img style="width: 240px" align="middle" src='./images/eqvi.png'></div>
        </td>
        <td align="left" valign="top" width="65%">
          <paper-title><a href="https://github.com/xinntao/Real-ESRGAN" target="_blank"><b>EQVI</b>: Training
              Real-World Blind Super-Resolution with Pure Synthetic Data</a>
          </paper-title>
          <div class=" paper-info">
            <a href="https://scholar.google.com/citations?user=WRIYcNwAAAAJ&hl=en&oi=ao">Yihao Liu*</a>,
            <b>Liangbie Xie*</b>,
            <a href="https://scholar.google.com/citations?user=83WWEs4AAAAJ&hl=en">Li Siyao</a>,
            <a href="https://scholar.google.com/citations?user=X9lE6O4AAAAJ&hl=en&oi=ao">Wenxiu Sun</a>,
            <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=en&oi=ao">Yu Qiao</a>,
            <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Chao Dong</a>,
            <br>
            <em>(* equal contribution) </em><br>
            <em>European Conference on Computer Vision Workshops (ECCVW), 2020.</em>
          </div>
          <span class=" block-text">
            <a href="https://arxiv.org/abs/2009.04642" target="_blank"> <strong>&nbsp;Paper
                (arXiv)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="https://github.com/lyh-18/EQVI" target="_blank"> <strong>&nbsp;Codes
                (GitHub)&nbsp;</strong></a></span>
          <span class=" block-text">
            <a href="projects/bib/eqvi_bib.html" target="_blank">
              <strong>&nbsp;BibTex&nbsp;</strong></a>
          </span>
        </td>
      </tr>

      </td>
      </tr>
    </table>
    <p align="left">
      <small>(* equal contribution, <sup>#</sup> corresponding author)</small>
    </p>
    <!-- <p>
      <center>
        <script type='text/javascript' id='clustrmaps'
          src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=67did0CAdncq-M1USj88a8nvNyHJzr771w9jz5KE4sQ&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'>
          </script>

        <br>
        &copy; Liangbin Xie | Last updated: January, 2021
      </center>
    </p> -->
    <span style="display: block; margin-bottom: 3em"></span>


    </p>
  </header>
</div>