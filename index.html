<head>
    <title>Liangbin Xie @UM</title>
    <meta name="author" content="Liangbin Xie">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Liangbin Xie @UM">
    <meta property="og:description" content="PhD student, University of Macau">
    <meta property="og:image" content="files/liangbinxie.jpg">
    <meta property="og:url" content="https://liangbinxie.github.io/">
    <!-- 	<meta name="twitter:card" content="summary_large_image"> -->
    <link rel="apple-touch-icon" href="files/uts-logo.png">
    <link rel="icon" type="image/png" href="files/uts-logo.png">
    <link rel="manifest" href="files/site.webmanifest">
    <link rel="stylesheet" href="style.css">
</head>

<div class="header noselect">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Liangbin Xie</h1>
            </div>
            <div class="header-subtitle">
                Jointly PhD student, University of Macau and Shenzhen
                Institute of
                Advanced Technology
            </div>
            <div class="header-links">
                <a class="btn" href="#contact">Email</a> /
                <!-- <a class="btn"
                    href="https://scholar.google.com/citations?view_op=list_works&hl=zh-CN&user=YpfrXyQAAAAJ">Google
                    Scholar</a> / -->
                <a class="btn" href="https://github.com/LiangbinXie">GitHub</a>
            </div>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 64px;">
    <div>
        <p>
            I am currently a jointly first-year (2022-now) Ph.D. student in University of Macau (UM) and Shenzhen
            Institute of
            Advanced Technology (SIAT),
            under the supervision of <a href="https://www.fst.um.edu.mo/personal/jtzhou/">Prof. Jiantao Zhou</a> and <a
                href=" https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Prof. Chao Dong</a>.
            Before that, I received master's degree in SIAT in 2022, under the supervision of <a
                href="https://mmcheng.net/cmm/">Prof. Chao Dong</a>.
        </p>

        <p>
            I am also a research intern (2020.12-now) in <a href="https://arc.tencent.com/zh/index">Tencent ARC Lab</a>
            ,
            working close to <a href="https://xinntao.github.io/">Dr. Xintao Wang</a>.
        </p>
    </div>
    <div>
        <h2 class="noselect">Research interest</h2>
        <p>
            My research interests include computer vision and deep learning, particularly focusing on image restoration
            and video restoration, <i>etc</i>.
        </p>
    </div>

    <div>
        <h2 class="noselect">News</h2>
        <ul>
            <li>
                [07/2022] One paper was accepted by ECCV 2022 as <b>oral</b> (2.7%).
            </li>
            <li>
                [05/2022] One paper was accepted by CVPR 2022 workshop.
            </li>
            <li>
                [12/2021] One paper was accepted by NeurIPS 2021 as <b>spotlight</b> (2.85%).
            </li>
            <li>
                [10/2021] One paper was accepted by ICCV 2021 AIM workshop with
                <b>Honorary Nomination Paper Award</b>.
            </li>
            <!-- <li>
                [12/2020] Join ARC Lab (Tencent PCG) as a research intern, work with <a
                    href="https://xinntao.github.io/">Xintao</a>.
            </li> -->
            <li>
                [08/2020] Our video interpolation method, <b>EQVI</b>, won the <a
                    href="https://data.vision.ee.ethz.ch/cvl/aim20/">AIM 2020
                    Challenge on Video Temporal Super-Resolution</a>
            </li>
        </ul>
    </div>

    <div>
        <h2 class="noselect">Publications</h2>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/ECCV22VQFR/ECCV22_VQFR.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2205.06803">VQFR: Blind Face Restoration
                    with Vector-Quantized Dictionary and Parallel Decoder</a><br />
                Yuchao Gu, Xintao Wang, <span class="bold">Liangbin Xie</span>, Chao Dong, Gen Li, Ying Shan and
                Ming-Ming Cheng<br />
                <span class="italic">European Conference on Computer Vision (<a
                        href="https://eccv2022.ecva.net/">ECCV</a>)</span>, 2022 (<span class="bold"
                    style="color: #f09228;">Oral</span>)<br />
                <a class="btn btn-orange" href="https://ycgu.site/projects/vqfr">project page</a>
                / <a class="btn btn-red" href="https://arxiv.org/abs/2205.06803">paper</a>
                / <a class="btn" href="https://github.com/TencentARC/VQFR">code</a>
                / <a class="btn btn-dark" href="files/ECCV22VQFR/gu2022vqfr.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/CVPRW22VFHQ/CVPRW22_VFHQ.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2205.03409">VFHQ:
                    A High-Quality Dataset
                    and Benchmark for Video Face Super-Resolution</a><br />
                <span class="bold">Liangbin Xie</span>, Xintao Wang, Honglun Zhang, Chao Dong and Ying Shan<br />
                <span class="italic">Computer Vision and Pattern Recognition Workshops (<a
                        href="https://data.vision.ee.ethz.ch/cvl/ntire22/">CVPRW</a>)</span>, 2022 <br />
                <a class="btn btn-orange" href="https://liangbinxie.github.io/projects/vfhq">project page</a>
                / <a class="btn btn-red"
                    href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Xie_VFHQ_A_High-Quality_Dataset_and_Benchmark_for_Video_Face_Super-Resolution_CVPRW_2022_paper.pdf">paper</a>
                <!-- / <a class="btn" href="files/ICCV21iNAS/iNAS_slide.pdf">slide</a> -->
                / <a class="btn" href="files/CVPRW22VFHQ/VFHQ_poster.pdf">poster</a>
                <!-- / <a class="btn" href="files/ICCV21iNAS/iNAS_video.mp4">video</a> -->
                / <a class="btn btn-dark" href="files/CVPRW22VFHQ/xie2022vfhq.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/NIPS21FAIG/NIPS21_FAIG.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2108.01070">Finding
                    Discriminative
                    Filters for Specific Degradations in Blind Super-Resolution</a><br />
                <span class="bold">Liangbin Xie*</span>, Xintao Wang*, Chao Dong, Zhongang Qi and Ying Shan<br />
                <span class="italic">Advances in Neural Information Processing Systems (<a
                        href="https://nips.cc/Conferences/2021">NIPS</a>)</span>, 2021 <br />
                <a class="btn btn-red" href="https://arxiv.org/abs/2108.01070">paper</a>
                / <a class="btn" href="https://github.com/TencentARC/FAIG">code</a>
                / <a class="btn" href="files/NIPS21FAIG/FAIG_slide.pdf">slide</a>
                / <a class="btn" href="files/NIPS21FAIG/FAIG_poster.pdf">poster</a>
                / <a class="btn btn-dark" href="files/NIPS21FAIG/xie2021faig.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/ICCVW21RealESRGAN/realesrgan.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2107.10833">Real-ESRGAN: Training
                    Real-World Blind Super-Resolution with Pure Synthetic Data</a><br />
                Xintao Wang, <span class="bold">Liangbin Xie</span>, Chao Dong and Ying Shan<br />
                <span class="italic">International Conference on Computer Vision Workshops (<a
                        href="https://data.vision.ee.ethz.ch/cvl/aim21/">ICCVW</a>)</span>, 2021 <br />
                <a class="btn btn-red"
                    href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.pdf">paper</a>
                / <a class="btn" href="https://github.com/xinntao/Real-ESRGAN">code</a>
                / <a class="btn" href="files/ICCVW21RealESRGAN/RealESRGAN_slide.pdf">slide</a>
                / <a class="btn" href="files/ICCVW21RealESRGAN/RealESRGAN_poster.pdf">poster</a>
                / <a class="btn btn-dark" href="files/ICCVW21RealESRGAN/wang2021realesrgan.txt">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(files/ECCVW20EQVI/eqvi.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2009.04642">Enhanced Quadratic Video
                    Interpolation</a><br />
                Yihao Liu*, <span class="bold">Liangbin Xie*</span>, Li Siyao, Wenxiu Sun, Yu Qiao and Chao Dong<br />
                <span class="italic">European Conference on
                    Computer Vision Workshops (<a href="https://data.vision.ee.ethz.ch/cvl/aim21/">ECCVW</a>)</span>,
                2020 <br />
                <a class="btn btn-red"
                    href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.pdf">paper</a>
                / <a class="btn" href="https://github.com/lyh-18/EQVI">code</a>
                <!-- / <a class="btn" href="files/ICCVW21RealESRGAN/RealESRGAN_slide.pdf">slide</a>
                / <a class="btn" href="files/ICCVW21RealESRGAN/RealESRGAN_poster.pdf">poster</a> -->
                / <a class="btn btn-dark" href="files/ECCVW20EQVI/liu2020eqvi.txt">bibtex</a>
            </div>
        </div>
    </div>

    <!-- <div class="noselect">
        <a id="honor"></a>
        <h2>Honors and Awards</h2>
        <p>
            Outstanding Graduates, Nankai University, 2022<br>
            Nankai - SK Hynix Outstanding Research Scholarship, 2022<br>
            The First Prize Gongneng Scholarship of graduate school, Nankai University, 2020-2022<br>
            National Scholarship of Ministry of Education, Government of China, 2018<br>
        </p>
    </div> -->

    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me regarding my research. I typically respond within a few days.<br />
        I can be contacted directly at <span class="bold">lb.xie</span> [at] siat.ac.cn
    </div>
</div>
<div class="footer noselect">
    <div class="footer-content">
        Thanks for the website design from Nicklas Hansen <a href="https://nicklashansen.github.io/">here</a>.
    </div>
</div>