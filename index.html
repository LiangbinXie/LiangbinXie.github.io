<!DOCTYPE html>
<!-- saved from url=(0025)https://LiangbinXie.github.io/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<link rel="shortcut icon" href="https://qinghonglin.github.io/myIcon.ico">
	<meta name="google-site-verification" content="PcjE-PoDvp7KoKeZ5wE1g_BU8VI5wioTfiAgbIst__4" />
	<meta name="keywords" content="Liangbin Xie">
	<meta name="description" content="Liangbin Xie&#39;s homepage">
	<!-- <link rel="icon" href="icon.ico" type="figures/emoji"> -->
	<!-- <link rel="shortcut icon" href="https://em-content.zobj.net/thumbs/120/apple/325/technologist-light-skin-tone_1f9d1-1f3fb-200d-1f4bb.png"> -->
	<link rel="shortcut icon" href="https://em-content.zobj.net/thumbs/120/apple/325/snowflake_2744-fe0f.png">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<title>Liangbin Xie @ University of Macau</title>
	<script async="" src="./index_files/analytics.js"></script>
	<script type="text/javascript" async="" src="./index_files/ga.js"></script>
	<script type="text/javascript">
		var _gaq = _gaq || [];
		_gaq.push(['_setAccount', 'UA-39824124-1']);
		_gaq.push(['_trackPageview']);
		(function () {
			var ga = document.createElement('script');
			ga.type = 'text/javascript';
			ga.async = true;
			ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			var s = document.getElementsByTagName('script')[0];
			s.parentNode.insertBefore(ga, s);
		})();
	</script>
</head>

<body>
	<div id="layout-content" style="margin-top:25px">
		<!-- <table> -->
		<table style="margin-bottom: -20px;">
			<tbody>
				<tr>
					<td width="670">
						<div id="toptitle">

							<h1>Liangbin Xie</h1>
						</div>
						<h3>Ph.D. Student</h3>
						<p>
							<a href="https://xpixel.group/">Xpixel Group</a><br />
							<a href="https://www.um.edu.mo/">University of Macau</a><br />
							<br>
							Email: <u><a href="mailto:lb.xie@siat.ac.cn">lb.xie [at] siat.ac.cn</a></u>
						</p>
						<p>
							<a href="https://github.com/LiangbinXie"><img src="./index_files/github.png"
									height="30px"></a>
							<a href="https://scholar.google.com/citations?user=auQhf5EAAAAJ&hl=en"><img
									src="./index_files/google_scholar.png" height="30px"></a>
						</p>
					</td>
					<td>
						<img src="./files/liangbinxie.jpg" border="0" width="200"><br>
					</td>
				</tr>
				<tr>
				</tr>
			</tbody>
		</table>

		<h2>Biography</h2>
		<p>
		</p>
		<div style="text-align:justify">
			I am currently a jointly second-year (2022-now) Ph.D. student in University of Macau (UM) and Shenzhen
			Institute of
			Advanced Technology (SIAT),
			under the supervision of <a href="https://www.fst.um.edu.mo/personal/jtzhou/">Prof. Jiantao Zhou</a> and <a
				href=" https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ" target="_blank">Prof. Chao Dong</a>.
			Before that, I received master's degree in SIAT in 2022, under the supervision of <a
				href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ">Prof. Chao Dong</a>.
			<p></p>
			<p>My research interests lie in <b>AIGC</b>, especially in Image Generation/Editing.

			<h2>News</h2>
			<ul>
				<li>
					2023 April: One paper was accepted by <a href="https://icml.cc/Conferences/2023"> ICML 2023</a>.
				</li>
				<li>
					2022 Nov: One paper was accepted by <a href="https://aaai-23.aaai.org/"> AAAI 2023</a>.
				</li>
				<li>
					2022 Sept: One paper was accepted by <a href="https://nips.cc/">NeurIPS 2022</a>.
				</li>
				<li>
					2022 July: One paper was accepted by <a href="https://eccv2022.ecva.net/"></a> ECCV 2022 as
					<b>oral</b> (2.7%).
				</li>
				<li>
					2021 Dec: One paper was accepted by <a href="https://nips.cc/Conferences/2021"></a>NeurIPS 2021 as
					<b>spotlight</b> (2.85%).
				</li>
				<li>
					2020 Aug: <b>EQVI</b>, won the <a href="https://data.vision.ee.ethz.ch/cvl/aim20/">AIM 2020
						Challenge on Video Temporal Super-Resolution</a>.
				</li>
			</ul>

			<h2>Publications</h2>
			<table id="tbPublications" width="100%">
				<tbody>
					<tr>
						<td width="260">
							<img src="files/StyleAdapter/StyleAdapter.png" width="240px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2302.08453.pdf"><b>StyleAdapter: A Single-Pass LoRA-Free
									Model for
									Stylized Image Generation</b></a> <br>
							Zhouxia Wang, Xintao Wang, <b>Liangbin Xie</b>, Zhongang Qi, Ying
							Shan, Wenping Wang and Ping Luo.<br>
							<p style="margin-top:3px">
								<em>Arxiv, </em>2023.<br>
								[<a href="https://arxiv.org/abs/2302.08453.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/T2I-Adapter">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/T2IAdapter/T2IAdapter.png" width="240px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2302.08453.pdf"><b>T2I-Adapter: Learning Adapters to Dig
									out
									More Controllable Ability for
									Text-to-Image Diffusion Models</b></a> <br>
							Chong Mou, Xintao Wang, <b>Liangbin Xie</b>, Yanze Wu, Jian Zhang, Zhongang Qi, Ying Shan
							and Xiaohu Qie.<br>
							<p style="margin-top:3px">
								<em>Arxiv, </em>2023.<br>
								[<a href="https://arxiv.org/abs/2302.08453.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/T2I-Adapter">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/ICML2023/DeSRA.jpg" width="240px" style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/pdf/2307.02457.pdf"><b>DeSRA: Detect and Delete the Artifacts of
									GAN-based Real-World
									Super-Resolution Models</b></a> <br>
							<b>Liangbin Xie*</b>, Xintao Wang*, Xianyu Chen*, Gen Li, Ying Shan, Jiantao Zhou and
							Chao Dong.<br>
							<p style="margin-top:3px">
								<em>International Conference on Machine Learning (<b>ICML</b>), </em>2023.<br>
								[<a href="https://arxiv.org/pdf/2307.02457.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/DeSRA">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/AAAI23FastRealVSR/AAAI23_FastRealVSR.jpg" width="240px" height="150px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/pdf/2212.07339.pdf"><b>Mitigating Artifacts in Real-World Video
									Super-Resolution
									Models</b></a> <br>
							<b>Liangbin Xie</b>, Xintao Wang, Shuwei Shi, Jinjin Gu, Chao Dong and Ying Shan.<br>
							<p style="margin-top:3px">
								<em>Proceedings of the AAAI Conference on Artificial Intelligence (<b>AAAI</b>),
								</em>2023.<br>
								[<a href="https://arxiv.org/pdf/2212.07339.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/FastRealVSR">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/NIPS22PSRT/psrt.jpg" width="240px" height="150px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2207.08494.pdf"><b>Rethinking Alignment in Video
									Super-Resolution Transformers</b></a> <br>
							Shuwei Shi*, Jinjin Gu*, <b>Liangbin Xie</b>, Xintao Wang, Yujiu Yang,
							and Chao Dong
							<p style="margin-top:3px">
								<em>Advances in Neural Information Processing Systems (<b>NIPS</b>),
								</em>2022.<br>
								[<a href="https://arxiv.org/abs/2207.08494.pdf">paper</a>]
								[<a href="https://github.com/XPixelGroup/RethinkVSRAlignment">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/ECCV22VQFR/ECCV22_VQFR.png" width="240px" height="120px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2205.06803"><b>VQFR: Blind Face Restoration
									with Vector-Quantized Dictionary and Parallel Decoder</b></a> <br>
							Yuchao Gu, Xintao Wang, <b>Liangbin Xie</b>, Chao Dong, Gen Li, Ying Shan and
							Ming-Ming Cheng.<br>
							<p style="margin-top:3px">
								<em>International Conference on Computer Vision (<b>ICCV</b>), </em>2022.<br>
								[<a href="https://ycgu.site/projects/vqfr/">project</a>]
								[<a href="https://arxiv.org/abs/2205.06803.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/VQFR">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/CVPRW22VFHQ/CVPRW22_VFHQ.png" width="240px" height="150px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2205.03409"><b>VFHQ:
									A High-Quality Dataset
									and Benchmark for Video Face Super-Resolution</b></a> <br>
							<b>Liangbin Xie</b>, Xintao Wang, Honglun Zhang, Chao Dong and Ying
							Shan<br />
							<p style="margin-top:3px">
								<em>Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>), </em>2022.<br>
								[<a
									href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Xie_VFHQ_A_High-Quality_Dataset_and_Benchmark_for_Video_Face_Super-Resolution_CVPRW_2022_paper.pdf">paper</a>]
								[<a class="btn btn-orange" href="https://liangbinxie.github.io/projects/vfhq">project
									page</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/NIPS21FAIG/NIPS21_FAIG.png" width="240px" height="120px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2108.01070"><b>Finding
									Discriminative
									Filters for Specific Degradations in Blind Super-Resolution</b></a> <br>
							<b>Liangbin Xie*</b>, Xintao Wang*, Chao Dong, Zhongang Qi and Ying Shan.<br>
							<p style="margin-top:3px">
								<em>Advances in Neural Information Processing Systems (<b>NIPS</b>), </em>2021.<br>
								[<a href="https://arxiv.org/abs/2108.01070.pdf">paper</a>]
								[<a href="https://github.com/TencentARC/FAIG">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/ICCVW21RealESRGAN/realesrgan.jpg" width="240px" height="120px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2107.10833"><b>Real-ESRGAN: Training
									Real-World Blind Super-Resolution with Pure Synthetic Data</b></a> <br>
							Xintao Wang, <b>Liangbin Xie</b>, Chao Dong and Ying Shan.
							<p style="margin-top:3px">
								<em>International Conference on Computer Vision Workshops (<b>ICCVW</b>), </em>2021.<br>
								[<a
									href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.pdf">paper</a>]
								[<a href="https://github.com/xinntao/Real-ESRGAN">code</a>]
								<br>
						</td>
					</tr>
					<tr>
						<td width="260">
							<img src="files/ECCVW20EQVI/eqvi.png" width="240px" height="100px"
								style="box-shadow: 4px 4px 8px #888">
						</td>
						<td><a href="https://arxiv.org/abs/2009.04642"><b>Enhanced Quadratic Video
									Interpolation</b></a>
							<br>
							Yihao Liu*, <b>Liangbin Xie*</b>, Li Siyao, Wenxiu Sun, Yu Qiao and Chao Dong.<br>
							<p style="margin-top:3px">
								<em>European Conference on
									Computer Vision Workshops (<b>ECCVW</b>), </em>2020. <font color="#FF0000">
								</font><br>
								[<a
									href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.pd">paper</a>]
								[<a href="https://github.com/lyh-18/EQVI">code</a>]
								<br>
						</td>
					</tr>
					<tr></tr>
					<tr></tr>
				</tbody>
			</table>
			</ul>

			<!--
	<li>
		<div style="float:left; text-align:left">2nd Place on Ego4D - Natural Language Queries Challenge, CVPR</div> <div style="float:right; text-align:right">2022</div>
	</li>
-->
			<!-- <li>
					<div style="float:left; text-align:left">AAAI Student Scholarship</div>
					<div style="float:right; text-align:right">2022</div>
				</li>
				<li>
					<div style="float:left; text-align:left">SIGIR Student Travel Grant</div>
					<div style="float:right; text-align:right">2021</div>
				</li> -->
			<!--	<li>
		<div style="float:left; text-align:left">Outstanding Graduate at SZU</div> <div style="float:right; text-align:right">2022, 2019</div>
	</li>
-->


			<h2>Service</h2>
			<ul>
				<li>
					<p>Conference Reviewer: CVPR, ICCV, ECCV, ICLR, NIPS, etc.</p>
				</li>
				<li>
					<p>Journal Reviewer: TPAMI, IJCV, TNNLS, TMM, etc.</p>
				</li>
			</ul>

			</tbody>
			</table>
			<h2>Acknowledgment</h2>
			I have been fortunate to work with these wonderful people who generously provided me with mentorship..
			<table
				style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
				<tbody>
					<tr>
						<td style="padding:1%;width:20%;vertical-align:top">
							<p align="">
								<img style="width:100%" align="center" src="files/tencent.jpg" class="hoverZoomLink">
							<p align="center">
								<a href="https://www.tencent.com/">@ Tencent</a>
								<br>
							<p align="center">
								<a href="https://scholar.google.com/citations?user=AjxoEpIAAAAJ&hl=zh-CN">Dr. Xintao
									Wang</a>
								<br>
							</p>
						</td>

						<td> </td>
						<td> </td>
						<td> </td>
				</tbody>
			</table>


			<div align="center">

				<body>
					<font color="gray">&copy Liangbin Xie</font>
				</body>
			</div>

			<script>
				(function (i, s, o, g, r, a, m) {
					i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
						(i[r].q = i[r].q || []).push(arguments)
					}, i[r].l = 1 * new Date(); a = s.createElement(o),
						m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
				})(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

				ga('create', 'UA-88615920-1', 'auto');
				ga('send', 'pageview');
			</script>
		</div>
	</div>
</body>

</html>