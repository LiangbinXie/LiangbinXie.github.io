<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="VFHQ.">
  <meta name="keywords" content="Video Face Dataset, High-Quality, Face Video Super Resolution">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VFHQ</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://liangbinxie.github.io/">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <!-- <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://hypernerf.github.io">
              HyperNeRF
            </a>
            <a class="navbar-item" href="https://nerfies.github.io">
              Nerfies
            </a>
            <a class="navbar-item" href="https://latentfusion.github.io">
              LatentFusion
            </a>
            <a class="navbar-item" href="https://photoshape.github.io">
              PhotoShape
            </a>
          </div>
        </div> -->
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <font color="Tomato">VFHQ</font>: A <font color="Tomato">H</font>igh-<font color="Tomato">Q</font>uality
              Dataset and Benchmark for <font color="Tomato">V</font>ideo <font color="Tomato">F</font>ace Super
              Resolution
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://LiangbinXie.github.io/">Liangbin Xie</a>
                <sup>1,2,3</sup>,</span>
              <span class="author-block">
                <a href="https://xinntao.github.io/">Xintao Wang</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=KjQLROoAAAAJ">Honglun Zhang</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=OSDCB0UAAAAJ&hl=zh-CN">Chao Dong</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en">Ying Shan</a><sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shenzhen Key Lab of Computer Vision and Pattern Recognition, <br>
                Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences.<br></span>
              <span class="author-block"><sup>2</sup>University of Chinese Academy of Sciences.</span>
              &nbsp;&nbsp;
              <span class="author-block"><sup>3</sup>ARC Lab, Tencent PCG.</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Xie_VFHQ_A_High-Quality_Dataset_and_Benchmark_for_Video_Face_Super-Resolution_CVPRW_2022_paper.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2205.03409" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="80%">
          <source src="./static/images/teasor.mp4" type="video/mp4">
        </video>
        <!-- <h2 class="subtitle has-text-centered">
          <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
          free-viewpoint
          portraits.
        </h2> -->
      </div>
    </div>
  </section>


  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section> -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Most of the existing video face super-resolution (VFSR) methods are trained and evaluated on VoxCeleb1,
              which is designed specifically for speaker identification and the frames in this dataset are of low
              quality. As a consequence, the VFSR models trained on this dataset can not output visual-pleasing results.
              In this paper, we develop an automatic and scalable pipeline to collect a high-quality video face dataset
              (VFHQ), which contains over <b>16,000 high-fidelity clips</b> of <b>diverse interview scenarios</b>. To
              verify
              the necessity of VFHQ, we further conduct experiments and demonstrate that VFSR models trained on our VFHQ
              dataset can generate results with sharper edges and finer textures than those trained on VoxCeleb1. In
              addition, we show that the temporal information plays a pivotal role in eliminating video consistency
              issues as well as further improving visual performance. Based on VFHQ, by analyzing the benchmarking study
              of several state-of-the-art algorithms under bicubic and blind settings.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <hr />
  <section class="section">
    <div class="container is-max-desktop">
      <!-- High Quality. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-4">Characteristics — High Quality and Diverse</h2>
          <div class="content has-text-justified">
            <video id="high_qulity" autoplay muted loop playsinline height="100%">
              <source src="./static/images/quality1.mp4" type="video/mp4">
            </video>
            <div class="content has-text-centered">
              <p>
                The clips in VFHQ are high-quality.
              </p>
            </div>
            <div class="content has-text-justified">
              <video id="high_qulity" autoplay muted loop playsinline height="100%">
                <source src="./static/images/quality2.mp4" type="video/mp4">
              </video>
              <div class="content has-text-centered">
                <p>
                  The scenarios in VFHQ are diverse.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <hr />
  <section class="section">
    <div class="container is-max-desktop">

      <!-- Statistics. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Statistics</h2>
          <div class="content has-text-justified">
            <img src="static/images/statistic1.jpg" class="interpolation-image"
              alt="Interpolation end reference image." />
            <p class="is-bold">As shown in (a), VFHQ
              includes
              persons that come from more than 20 distinct countries. In (b), we notice that the proportion of men and
              women is
              roughly the same.</p>
          </div>
          <div class="content has-text-justified">
            <img src="static/images/statistic2.jpg" class="interpolation-image"
              alt="Interpolation end reference image." />
            <p class="is-bold">The figure (c)
              demonstrates that the distribution of clip resolution of our VFHQ is
              different from
              VoxCeleb1 and the resolution of VFHQ is much higher than VoxCeleb1. Above the bar is the number of clips.
              Note that we
              use the length of the shortest side as the clip resolution. The figure (d) shows that the quality of VFHQ
              is higher than
              VoxCeleb1 quantitatively.</p>
          </div>
          <br />
          <!--/ Interpolating. -->

          <!-- Re-rendering. -->
          <!-- <h3 class="title is-3">Benefits of VFHQ</h3>
          <div class="content has-text-justified">
            <p>
              Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
              viewpoint such as a stabilized camera by playing back the training deformations.
            </p>
          </div>
          <div class="content has-text-centered">
            <video id="replay-video" controls muted preload playsinline width="75%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/replay.mp4" type="video/mp4">
            </video>
          </div> -->
          <!--/ Re-rendering. -->

        </div>
      </div>

    </div>
  </section>
  <hr />
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 ">Agreement</h2>
          <div class="content has-text-justified">

            <ul>
              <li> The VFHQ dataset is only available to download for non-commercial research purposes. The copyright
                remains with the original owners of the video. A complete
                version of the license can be found <a href="./license.txt">here</a> and we refer to the
                license of <a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/">VoxCeleb</a>. </li>
              <li>All videos of the VFHQ dataset are obtained from the Internet which are not property of
                our institutions. Our institution are not responsible for the content nor the meaning
                of these videos. </li>
              <li>You agree not to reproduce, duplicate, copy, sell, trade, resell or exploit for any
                commercial purposes, any portion of the videos and any portion of derived data.</li>
              <li>You agree not to further copy, publish or distribute any portion of the VFHQ
                dataset. Except, for internal use at a single site within the same organization it is allowed to
                make copies of the dataset.</li>
              <li>The distribution of identities in the VFHQ datasets may not be representative of the global human
                population. Please be careful of unintended societal, gender, racial and other biases when training or
                deploying models trained on this data.</li>
            </ul>

  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <!-- <div class="column is-four-fifths"> -->
        <div class="column is-four-fifths">
          <h2 class="title is-3 "> Dataset</h2>
          <div class="content has-text-justified">
            <p class="text-justify">We provide a processing script that extracts
              high-resolution faces from meta info. In addition, if you want the processed VFHQ dataset or
              the resized 512x512 version, please
              contact
              us.
            </p>
            <div>
              <table>
                <tr>
                  <td>
                    <figure>
                      <img src="static/images/folders.png" , width="30%"><br><br>
                      <span class="block-text">
                        <a href="https://1drv.ms/u/s!Ag1HH_EDGMqqh2OkSCrp4Ql3i17Q?e=ZTvUAP" target="_blank">
                          <strong>&nbsp;VFHQ Meta info(OneDrive)&nbsp;</strong></a></span><br><br>
                      <span class=" block-text">
                        <a href="https://share.weiyun.com/RB8c5NlN" target="_blank"> <strong>&nbsp;VFHQ Meta info
                            (腾讯微云)&nbsp;</strong></a></span>
                    </figure>
                  </td>

                  <td>
                    <figure>
                      <!-- <a href="https://github.com/CelebV-HQ/CelebV-HQ/blob/main/celebvhq_info.json">
                    <img src="static/img/download_icon.jpeg" height="80px" width="100px" alt="download">
                    <figcaption> Annotations </figcaption>
                  </a> -->
                      <img src="static/images/python_icon.png" , width="30%"><br><br>
                      <span class="block-text">
                        <a href="https://1drv.ms/u/s!Ag1HH_EDGMqqh2e_C7_9L0tV-N7u?e=nYGlKg" target="_blank">
                          <strong>&nbsp;Processing Script (OneDrive)&nbsp;</strong></a></span><br><br>
                      <span class=" block-text">
                        <a href="https://share.weiyun.com/qr3k40jV" target="_blank"> <strong>&nbsp;Processing Script
                            (腾讯微云)&nbsp;</strong></a>
                      </span>
                    </figure>
                  </td>
                </tr>
              </table>
            </div>
          </div>
          <h2 class="title is-4 "> Dataset Structure</h2>
          <div class="content has-text-justified">
            <table border="1">
              <thead>
                <tr>
                  <th align="left">Path</th>
                  <th align="center">Size</th>
                  <th align="right">Files</th>
                  <th align="center">Format</th>
                  <th align="left">Description</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left"><a href="https://drive.google.com/open?id=1u2xu7bSrWxrbUxk-dT-UvEJq8IjdmNTP"
                      rel="nofollow">vfhq-dataset</a></td>
                  <td align="center">4.2 TB</td>
                  <td align="right">50,481</td>
                  <td align="center"></td>
                  <td align="left">Main folder</td>
                </tr>
                <tr>
                  <td align="left">├ <a href="https://drive.google.com/open?id=16N0RV4fHI6joBuKbQAoG34V_cQk7vxSA"
                      rel="nofollow">meta_info</a></td>
                  <td align="center">408 MB</td>
                  <td align="right">16,827</td>
                  <td align="center">JSON</td>
                  <td align="left">Metadata including video id, face landmarks, etc.</td>
                </tr>
                <tr>
                  <td align="left">├ <a href="https://drive.google.com/open?id=1LTBpJ0W_WLjqza3zdayligS8Dh1V1gA6"
                      rel="nofollow">VFHQ</a></td>
                  <td align="center">3 TB</td>
                  <td align="right">16,827</td>
                  <td align="center">PNG</td>
                  <td align="left"> Original VFHQ cropped from the YouTube videos.
                  </td>
                </tr>
                <tr>
                  <td align="left">└ <a href="https://drive.google.com/open?id=1WocxvZ4GEZ1DI8dOz30aSj2zT6pkATYS"
                      rel="nofollow">VFHQ-512</a></td>
                  <td align="center">1.2 TB</td>
                  <td align="right">16,827</td>
                  <td align="center">PNG</td>
                  <td align="left">Resized 512x512 version of VFHQ.</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </section>

  <hr />
  <section class="section" id="Citaton">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>If you find this helpful, please cite our work: </p>
      <pre><code>@InProceedings{xie2022vfhq,
      author = {Liangbin Xie and Xintao Wang and Honglun Zhang and Chao Dong and Ying Shan},
      title = {VFHQ: A High-Quality Dataset and Benchmark for Video Face Super-Resolution},
      booktitle={The IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
      year = {2022}
  }</code></pre>
    </div>
  </section>



  <footer class="footer">
    <div class="columns is-centered">
      <div class="content">
        <p> This template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io"> nerfies's
            webpage</a>.
        </p>
      </div>
    </div>
  </footer>

  <script>
    $(window).on('load', function () {
      $('#loading').hide();
    })
  </script>

</body>

</html>